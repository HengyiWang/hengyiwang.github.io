<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Boosting Video Object Segmentation Based on Scale Inconsistency</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
    <style>
      body {
        background: rgb(255, 255, 255) no-repeat fixed top left;
        font-family:'Open Sans', sans-serif;
      }
    </style>

  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container-fluid">
        <div class="row">
          <div class="col">
            <h2 style="font-size:30px;">Boosting Video Object Segmentation Based on Scale Inconsistency</h2>
            <h4 style="color:#6e6e6e;"> IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME) 2022 </h4>
            <hr>
            <h6> <a href="https://scholar.google.com/citations?user=2d9j2_wAAAAJ&hl=zh-CN" target="_blank">Hengyi Wang</a>, 
                 <a href="http://eecs.qmul.ac.uk/~coh/" target="_blank">Changjae Oh</a>
                 <br>
                 <br>
            <p> Queen Mary University of London &nbsp;
                <br>
            </p>
            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/abs/2205.01197" role="button" target="_blank">
                    <i class="fa fa-file"></i> Paper </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" id="code_soon" href="https://github.com/HengyiWang/SIRNet" role="button" target="_blank" disabled=1>
                <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <!-- <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" id="code_soon" href="https://davischallenge.org/" role="button" 
                    target="_blank" disabled=1>
                <i class="fa fa-github-alt"></i> Dataset </a> </p>
              </div> -->
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="icme22/videos/SuppleVideo.mp4" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Video</a> </p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h2>Abstract</h2>
             <hr style="margin-top:0px">
          <p class="text-justify">
            We present a refinement framework to boost the performance of 
            pre-trained semi-supervised video object segmentation (VOS) models. 
            Our work is based on scale inconsistency, which is motivated by the 
            observation that existing VOS models generate inconsistent predictions 
            from input frames with different sizes. We use the scale inconsistency 
            as a clue to devise a pixel-level attention module that aggregates the 
            advantages of the predictions from different-size inputs. The scale 
            inconsistency is also used to regularize the training based on a 
            pixel-level variance measured by an uncertainty estimation. We further 
            present a self-supervised online adaptation, tailored for test-time 
            optimization, that bootstraps the predictions without ground-truth masks 
            based on the scale inconsistency. Experiments on DAVIS 16 and DAVIS 17 
            datasets show that our framework can be generically applied to various 
            VOS models and improve their performance.
              
          </p>
        </div>
      </div>
    </div>
  </section>
    <br>
    
  <!-- Method -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h2>Method</h2>
             <hr style="margin-top:0px">
          <p class="text-justify">
            We aim to improve pre-trained VOS models (backbone model) using the multi-scale 
            context aggregation module with the scale inconsistency estimation (a). At test-time, 
            we further perform the self-supervised online adaptation that updates the model parameters 
            to reduce the accumulation of the errors over the frames, caused by the increase of the 
            scale inconsistency (b).
              
          </p>
        </div>
      </div>
      <div class="row" style="margin-top:5px">
        <div class="col-12 text-center">
          <img class="img-fluid" src="icme22/Overview.png" alt="">
        </div>
      </div>
    </div>
  </section>
    <br>
    

  <!-- Visual Comparison -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>Visual results</h2>
            <hr style="margin-top:0px">
            <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="icme22/videos/Gold-fish-osvos.webm" type="video/webm">
            </video>
            <br>
            <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="icme22/videos/moto-osvos.webm" type="video/webm">
            </video>
            <br>
            <br>
            <br>
            <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="icme22/videos/dog-RGMP.webm" type="video/webm">
            </video>
            <br>
            <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="icme22/videos/camel-RGMP.webm" type="video/webm">
            </video>
            <br>
            <br>
            <br>
            <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="icme22/videos/soapbox-stm.webm" type="video/webm">
            </video>
            <br>
            <video width="90%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="icme22/videos/ski-stm.webm" type="video/webm">
            </video>
            
        </div>
      </div>
    </div>
  </section>
  <br>
  

  <!-- Reference -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h3>Reference</h3>
             <hr style="margin-top:0px">
          <p class="text-justify">
            <center>
            <table id="ref" border="1" width="98%">
              <thead>
              <tr>
                  <th>Name</th>
                  <th>Title</th>
                  <th>Year</th>
                  <th>Author</th>
                  <th>Paper</th>
  
              </tr>
              </thead>
  
              <tbody>
              <tr>
                  <td class="phy">OSVOS</td>
                  <td>One-shot video object segmentation
                  </td>
                  <td>2017</td>
                  <td>S. Caelles <i>et al.</i></td>
                  <td><a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Caelles_One-Shot_Video_Object_CVPR_2017_paper.pdf" target="_blank">[Paper]</a>
                  </td>
              </tr>
              <tr>
                  <td class="phy">RGMP</td>
                  <td>Fast video object segmentation by reference-guided mask propagation</td>
                  <td>2018</td>
                  <td>S-W. Oh <i>et al.</i></td>
                  <td><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Oh_Fast_Video_Object_CVPR_2018_paper.pdf" target="_blank">[Paper]</a></td>
              </tr>
              <tr>
                  <td class="phy">STM</td>
                  <td>Video object segmentation using space-time memory networks</td>
                  <td>2019</td>
                  <td>S-W. Oh <i>et al.</i></td>
                  <td>
                      <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Oh_Video_Object_Segmentation_Using_Space-Time_Memory_Networks_ICCV_2019_paper.pdf" target="_blank">[Paper]</a></td>
              </tr>
  
          </tbody></table>
          </center>
          </p>
        </div>
      </div>
    </div>
  </section>
    <br>



  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@article{wang2022boosting,
    title={Boosting Video Object Segmentation based on Scale Inconsistency},
    author={Wang, Hengyi and Oh, Changjae},
    journal={IEEE International Conference on Multimedia and Expo (ICME)},
    year={2022}
  }
  </code></pre>
      </div>
    </div>
  </div>



  <footer class="text-center" style="margin-bottom:10px; font-size: medium;">
      <hr>
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the <a href="https://lioryariv.github.io/idr/" target="_blank">website template</a>.
  </footer>
  <script>
    MathJax = {
      tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</body>
</html>